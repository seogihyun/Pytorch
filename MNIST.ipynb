{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYoFqfzELCD8"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision import transforms, datasets\r\n",
        "\r\n",
        "torch.manual_seed(4179)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UOJ1tQaMWel"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device('cuda' if use_cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHvhzmvMfQc"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjQFqh-4Mfxr"
      },
      "source": [
        "epochs = 30\r\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc216PbsYoLF"
      },
      "source": [
        "datasets.MN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvxiWjU6WQMO"
      },
      "source": [
        "transform_train = transforms.Compose([\r\n",
        "    transforms.RandomHorizontalFlip(),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "transform_test = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "trainset = datasets.FashionMNIST(\r\n",
        "    root = './.data/',\r\n",
        "    train = True,\r\n",
        "    download = True,\r\n",
        "    transform = transform_train\r\n",
        ")\r\n",
        "testset = datasets.FashionMNIST(\r\n",
        "    root = './.data/',\r\n",
        "    train = False,\r\n",
        "    download = True,\r\n",
        "    transform = transform_test\r\n",
        ")\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    dataset = trainset,\r\n",
        "    batch_size = batch_size,\r\n",
        "    shuffle = True,\r\n",
        ")\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    dataset = testset,\r\n",
        "    batch_size = batch_size,\r\n",
        "    shuffle = True,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei6_BF4wYyOU"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST('./.data',\r\n",
        "                   train=True,\r\n",
        "                   download=True,\r\n",
        "                   transform=transforms.Compose([\r\n",
        "                      transforms.RandomHorizontalFlip(),\r\n",
        "                      transforms.ToTensor(),\r\n",
        "                      transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "                   ])),\r\n",
        "    batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST('./.data',\r\n",
        "                   train=False,\r\n",
        "                   transform=transforms.Compose([\r\n",
        "                      transforms.ToTensor(),\r\n",
        "                      transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "                   ])),\r\n",
        "    batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJQWOmRKOTVv"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "  def __init__(self, dropout_p=0.2):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    self.fc1 = nn.Linear(784, 256)\r\n",
        "    self.fc2 = nn.Linear(256, 128)\r\n",
        "    self.fc3 = nn.Linear(128, 10)\r\n",
        "\r\n",
        "    self.dropout_p = dropout_p\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = x.view(-1, 784)\r\n",
        "    \r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.dropout(x, training=self.training, p=self.dropout_p)\r\n",
        "    \r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = F.dropout(x, training=self.training, p=self.dropout_p)\r\n",
        "\r\n",
        "    x = self.fc3(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNMroV20TEl-"
      },
      "source": [
        "model = Net(dropout_p=0.2).to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRa9mr9nTIpM"
      },
      "source": [
        "def train(model, train_loader, optimizer):\r\n",
        "  model.train()\r\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\r\n",
        "    data, target = data.to(device), target.to(device)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = model(data)\r\n",
        "    loss = F.cross_entropy(output, target)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "def evaluate(model, test_loader):\r\n",
        "  model.eval()\r\n",
        "  test_loss = 0\r\n",
        "  correct = 0\r\n",
        "  with torch.no_grad():\r\n",
        "    for data, target in test_loader:\r\n",
        "      data, target = data.to(device), target.to(device)\r\n",
        "      output = model(data)\r\n",
        "      test_loss += F.cross_entropy(output, target, reduction='sum').item()\r\n",
        "\r\n",
        "      pred = output.max(1, keepdim=True)[1]\r\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\r\n",
        "\r\n",
        "    test_loss /= len(test_loader.dataset)\r\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\r\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp5z-X2eVte9"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\r\n",
        "  train(model, train_loader, optimizer)\r\n",
        "  test_loss, test_accuracy = evaluate(model, test_loader)\r\n",
        "\r\n",
        "  print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaUMQFIDWGzk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}